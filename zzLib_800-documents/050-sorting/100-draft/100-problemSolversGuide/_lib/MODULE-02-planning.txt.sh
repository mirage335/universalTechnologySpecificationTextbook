
_heading2 'Planning'

_t '* ATTENTION: Immediate comprehension of the algorithmic, more similar to automation rather than cognition, planning process, is not necessary. Undertaking a few necessarily capital intense capital reducing complex projects (eg. commoditization by technological development) and referring back to this section will be more productive.'

_heading3 'Solvable Problem Complexity Limits - Entropy as a Limit, (Minimizing) Learning Curve'
_t 'Cognition solves problems by iteratively guessing at how a few interactions cause complex assemblies of objects to change observations of those objects. Evolutionary genetic algorithms impart a mutation, evaluated whether more or less optimal, on the ability to sustain more offspring over many generations. Neural networks (which may be optimized by evolutionary genetic algorithms) may attempt to model the relationship between interactions and changes in observations, evaluating such guesses internally, allowing useful &#39;intelligent&#39; behaviors with the low latency timeliness to catch &#39;Newton&#39;s proverbial falling apple&#39;.


Sufficient resources to contemplate every guess only exist when the number of objects (including assemblies of objects) in a guess is a very small number.


Humans evolved very quickly from a situation not as demanding of intelligence, and certainly not demanding of the symbolic manipulation of Player develops Automation which is devoid of problems more detailed than &#39;pocket calculator&#39; automation. Humans do not appreciate when their own happiness is clearly disregarded unnecessarily, even if otherwise comfortable.


Thus, any leader attempting success through humans performing Player develops Automation (ie. symbolic manipulation), must at every opportunity, minimize that, in favor of the entertainment of experimentation.


Learning curves result from multiplying impatience from symbolic manipulation effort with the perceived risk of uncertainty that such symbolic manipulation will be wrong and more effort will be demanded. Such risk increases exponentially with the number of guesses required, and combinations of solutions from previous symbolic manipulation without experimentation most risky of all. Few missed solutions without obvious benefit is discouraging enough, decades of learning is much to ask for, the many more years of self-invested &#39;higher education&#39; quite a lot of self-proving, especially if inefficient.

Some of the longest learning curves (ie. &#39;higher education&#39;) are imposed artificially, often with less pragmatic learning, as a measurement of Player develops Automation initiative - willingness to voluntarily take what is already conveniently experimented with as far as possible by adding as much symbolic manipulation as possible. When wealthy students have the luxury of expending more of their entire lives on unproductive effort, or when the bottom of Maslow&#39;s hierarchy of needs is imposed as motivation, such students involuntarily complete increasingly artificially long learning curves, without any particular voluntary interest in any technical success. Distinction of voluntary initiative then requires much longer learning curves. Other issues may be related, such as the small number of people (ie. cognition) able to usefully collaborate on a single project, combined with imaginary successes of much de-commoditization preventing these problems from being broken into separate problems, reducing the number of job opportunities for essential technology development, and slowing technological progress.

Independent developers expending their discretionary time into public effort for public benefit - free/libre open-source software &#39;FLOSS&#39; - are able to minimize such inflated learning curves. Voluntary initiative is visible in public repository histories, attributable on resumes due to absence of trade secrets, and corroborated by public discussion. Usefulness of such developers own voluntary inclinations can be inspected, which is not possible for those whose contributions are both involuntary and not publicly known.


Uncooperative attitudes and misinformation result when imaginary success by damaging mutual success is within the learning curve of the participants, but the understanding of solutions which result in real success requires too much Player develops Automation symbolic manipulation, not within the learning curve of the participants. Beyond that, when participants do not have sufficient margin in their daily lives - misinformation can be permanently accepted, and tolerance for diversity is eroded for no other reason.

Such are inherent &#39;soft limits&#39; of cognition, which must not be underestimated, always the first obstacle to progress in a development transition, from no wealth to any, much less equally unlimited, wealth, from biological to technological. Derision of a less inflated learning curve is highly inappropriate, minimizing the learning curve, highly appropriate.'



_heading3 'Search for Solutions'

_t 'Player develops Automation problems of any complexity are combinations of machines which each implement specific consequential effects (ie, resistors, capacitors, inductors, amplifiers), or rarely (usually due to very high performance requirements) mechanisms which simultaneously implement specific consequential effects (eg. springs, quartz crystal oscillators). Due to this combinational nature, such problems are solvable by an algorithm more akin to Chess, than than other games, evaluating as many strategies as possible, and evaluating strategies from every scenario following the use of each of those strategies. Such algorithms are close to if not in fact &#39;automated planning&#39;, best-effort &#39;state space search&#39;, etc.

Such planning may contemplate all possible consequential effects of an implementation, identify all possible modules combining these implementations, and either perform experiments to model the usability of those combinations, or use existing models to internally evaluate possible guesses.

When planning is bringing better solutions, planning should continue until the point of diminishing returns. If planning is not bringing conclusions of either better solutions or absence of solutions, reduction of problem to smaller search spaces, to allow fewer guesses, is appropriate.'


_heading3 'Reduction of Problem to Smaller Search Spaces'

_t 'When usable solutions are not obvious, more implementations of specific consequential effects (ie, arrangements of resistors, capacitors, inductors, amplifiers) must be designed. When design is not practical, experiments must improve modeling (eg. educating one&#s own intuition, or developing simulation software), or design software (eg. CAD modeling software) must be improved.

More simply put, when technological knowledge is not sufficient to identify an obvious solution, the problem may not be solvable without more technology development. Such is the extent of modern science that this is rarely if ever a problem today (usually only in very high performance air-breathing engine technology and some other energy production technology).

When the problem is reduced to problems which require a small number of guesses, after which further reduction is a point of diminishing returns, that is the time to solve the problem.'




_heading3 'Internal Modeling by Internal Simulation from Recent Observation'

_t 'One approach to self-driving AI is to observe the environment, model this as a virtual WORLD in a game engine, simulate several solutions from cognition (ie. artificial neural network), evaluate predicted scenarios for desirability after multiple rounds of possible interactions, and select the best path. Vaguely similar to solving chess.

Such may be illustrative of the problem solving process, and could in principle, however slowly and with however much complexity in the conversion from observation to virtual WORLD, solve all mining, manufacturing, maintenance, computing, energy generation, etc, problems, without actually taking unnecessary actions (eg. due to &#39;Sussman Anomaly&#39;). As an oversimplification, such misses many substantial optimizations. Neural networks may be better able to identify and predicatively evaluate scenarios by object pattern recognition without resorting to completely accurate modeling of the environment. Evaluation of predicted scenarios over multiple rounds as with chess may not be a very efficient if some directions can be excluded for not having significant gain (ie. moving away from a cluster of obstacles and towards a workpiece avoids obviously unhelpful collisions with all of them).'






_heading3 'Qualifying Help and Proposals by Plausibility of Relevant Consequential Effects'

_t 'At least a partial understanding of planning techniques improves a person&#39;s own ability, especially if irrationally impatient, to quickly find enough information to seek good help.


As an example, perhaps we want to make sounds louder. Supposing information on tools to do this is not readily available, we could consider a more generic search, a more solvable problem. Looking for related events, flipping a light switch results in much more light energy is emitted. After some searches through bodies of scientific knowledge - notably internet and wikipedia search engines - we would discover the words &#39;amplification&#39;, &#39;multiplication&#39;, and &#39;gain&#39; are associated with this. Cross-referencing detailed encyclopedia articles regarding &#39;amplification&#39; would allow us to understand the scientific model of this phenomenon - mathematical multiplication of one signal by another. Engineering applications of the scientific model are referenced on a relevant encyclopedia page - circuits built around relays, vacuum tubes, and transistors, among others. We could conclude that gains of several hundred to one per low-cost transistor are usually available. Further investigation shows these are all electronic devices. From there, it can be inferred that someone skilled in electronics design may be prepared to pursue such a project on our behalf. We could then seek persons who have experience building amplifiers, or who are associated with such persons, to hire.

Even further investigation would quickly lead to discovery of related resistance, gain, voltage, and current characteristics of transistors, allowing us to construct a working amplifier from off-the-shelf parts ourselves.


Unfortunately, even a well meaning knowledgeable individual, can still be tempted to imaginary success in some way, especially at the expense of the exhaustive due diligence sometimes necessary. If technical personnel are theirselves not obviously satisfied that a point of diminishing returns has been reached finding more portable solutions to better minimize capital intensity, customer acceptance is unlikely.


Tool development, parts of which are sometimes referred to as &#39;science&#39; and &#39;engineering&#39; involve doing things completely dissimilar to what has been done before. Remaining difficulty and expected benefits is not a sunk cost argument, and must be contemplated. Some victories will be Pyrrhic.
' 
