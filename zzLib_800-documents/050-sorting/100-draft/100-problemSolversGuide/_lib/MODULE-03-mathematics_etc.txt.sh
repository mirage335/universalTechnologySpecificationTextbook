

_page ' ' ###

_heading2 'Mathematics'

_heading3 'Importance of Mathematics'

_t 'Arithemetic, algebra, calculus, and geometry concisely summarize relationships of practical use.
'

_t 'Arithemetic as addition, subtraction, multiplication, and division, is the consequence of finite &#39;quantity&#39; in the universe. Arithmetic is familiar for tallying suppies, however, it is addition and subtraction that make feedback possible, which allows the motivation of any machine whether cognition (often using neural networks) or automation (often using op-amps or logic gates). Arithmetic multiplication over time shifts the frequency at which things happen, meaning any shift in amplitude (any addition or subtraction of a signal) is also a multiplication of frequency, which has the essential application of frequency mixing (eg. shifting a narrow range of frequencies at >>100MHz to <<1kHz audio for radio reception or reverse for radio transmission).

Algebra allows calculation of specific elements in systems of equations to be calculated, by recognizing that operation on a variable is equal to the inverse operation on a variable which the original variable is dependent on. Modern TI-68k series (TI-89/TI-92[+]/V200/Voyage 200 [PLT]) calculators including the Derive CAS software have unmatched capability to handle especially complex systems of equations, correctly accepting and outputting boolean and/or operators. Wolfram Alpha, Qualculate, and other CAS software have similar, though less robust, capability. Convenient access to algebric (and arithmetic) functions is available through UNIX/Linux/Cygwin interactive command prompts and scripts using Qalculate, GNU Octave, backends contained by &#39;ubiquitous bash&#39; .

Calculus relates functions to formulas for the rate of change with another variable. Differentation and integration are the primary operators. Again, modern TI-68k series calculators offer excellent support for these options, though other software is also available.

Geometry constructs complex shapes from simple relations of symmetry, parallelism, angles, and distances. Modern CAD software (especially FreeCAD with A2Plus) enables efficient exploration of these relationships.

Set theory and so-called relational &#39;algebra&#39; or &#39;calculus&#39; addresses collections of objects Operators include union, intersection, difference, and cartesion product. Such are common to &#39;database&#39; automation.

Persistent storage can be defined by just four operators - Create, Read, Update, and Delete (CRUD). Also known as Modify, Add, Delete, Show (MADS), When these operations are &#39;atomic&#39; - finishing before any other storage operation takes place - storage may be shared by multiple programs without risk of partial overwrites. Filesystems usually perform &#39;move&#39;, or equivalent &#39;rename&#39; so a temporary file (eg. unsaved text editor buffer) may overwrite a permanent file (eg. text file being edited) with less risk of damage (eg. due to power loss). Lock files (causing a program to wait until another program is no longer using a resources) commonly exploit the usual &#39;move&#39; filesystem feature.'



_heading3 'Mathematic Expression is usually a Poorly Used Language'

_t 'All of the observable universe can be described as a single computer instruction (ie. turing completeness), and is predominantly within the even narrower limits of the behavior of photons, electrons, and the (real or virtual) photons or phonons of photons transferring momentum between those particles.

Obviously, the vast majority of so-called &#39;mathematics&#39; is merely a convenient expression of relationships, often as an interesting discussion about how something works, without nearly sufficient information for any practical use.

For example, the Navier-Stokes equations describe fluid motion as a derivative of Newton&#39;s laws of motion. Certainly it is very interesting to contemplate that a fluid may be described as a bunch of individual particles which exert pressue on neighboring particles due to inertia. Actually simulating fluid motion requires convolving the interaction of every particle with every other particle in the fluid (expotentially more computational expense per particle), as well as having very precise units and constants which may not even be known precisely enough *for such well known fluid as water*. Practically simulating requires limiting such convolution to a limited number of neighboring particles, and/or limiting such convolution to speed-of-light mechanics (as seemingly common with Conway&#39;s game-of-life but beyond the scope of an equation written for a discussion narrowly focused on purely Newtonian classical mechanics). Software infrastructure to experiment (ie. &#39;play&#39;) with such particle grids in Virtual Reality may not really exist. Semingly obvious and simple software to perform such experiements may not exist to this day, hundreds of years after Newton&#39;s life, discoveries, and death. To the extent such software does exist, it may not be easily interoperable (eg. with game engines), may have some complexity, may be focused on useses narrower than real-time interaction (eg. &#39;Blender&#39;), and may be prohibitively expensive to license software made for any useful purpose that either professionals or amateurs would need (eg. &#39;Comsol&#39;).

Thus, it is entirely possible for a simple mathematical eqution to express something very interesting and useful, but with any useful implementation of it still a long way off, only due to all the useful details being left out, to the point that a single mathematical statement (ie. a One-Instruction Computer) is a more accurate description of the entire universe, than a single equation known for hundreds of years has been made useful today.'

_heading4 'Examples - When Mathematics are NOT Worthwhile'

_heading5 'SpaceX Starship'
_t 'SpaceX has been &#39;launching&#39; a number of &#39;Starships&#39;, and declaring these successful in their goals, despite spectacularly ending by &#39;crash-and-burn&#39;. Three things account for this &#39;success&#39;. First, the Starships theirselves are built for $millions, instead of the hundreds of $millions more usual of such large rockets, due to unprecedentedly inexpensive welded plate construction. Second, the apparent value of avoiding such spectacular melting of expensive rockets is offset by the cost of preparing simulations and/or licensing software to simulate, interactions between combusting fluits at complex temperature/density gradients and thin complex welded metals. Third, there may be no way at present for welding crews to practice such assembly in Virtual Reality, much less in any way capture the complex shapes they will form with their welds.

A &#39;crashed&#39; &#39;Starship&#39; may slag a couple million dollars in recyclable steel, while the seemingly expensive manufacturing processes of welding, etc, are actually what is under test, and if the software even exists to model of simulate what the welded joints of a &#39;Starship&#39; actually look like, it may cost more than a few million dollars to license for a suitable number of developers. Every &#39;Starship&#39; launch may more cheaply evaluate some particularly important aspect of the entire manufacturing process, cheaper and better, than any mathematical model and simulation.

Of cousrse, there are a lot more issues to &#39;Starship&#39; as well, such as pogo oscillation and continuing inertial navigation &#39;up&#39; instead of &#39;down&#39; while accelerometers are shaking, so this example is an oversimplification. Nevertheless, purely &#39;Newtonian&#39; physics known for hundreds of years remain easier to experiment with to the point of spending $millions rather than licensing expensive software.'

_heading5 'Flight Simulation'
_t 'Flight simulation costs a few tens of dollars per flight hour, or less. Accuracy has improved to the point of allowing players to repeatedly practice startup, avionics, and other procedures. Commercial aviation safety has no doubt improved much due to flight simulation.

Why then do exercises continue to be flown with real aircraft?

At least one reason is the need for practicing *everything else*. Readiness is about every job, not just the pilot&#39;s job. Much of the cost is in maintenance, and maintaining older aircraft is unpredictable, since simulation software to predict exactly where and how most aircraft will degrade over their useful lifetimes may not exist. Replacement of older aircraft with newer, better aircraft, is also necessary to practice as part of readiness for future activity. Especially, such things are true of aircraft designed for competitive use - where known science is already pushed to its limits, timely modeling to predict details of future degradation is not possible. Fuel costs may be a minority of such expenses, and all jobs must be practiced, all the way back to factory production of replacement aircraft.

Thus, flying real aircraft, albeit expensive, will continue, even as practice, even when software to accurately simulate part of the job, becomes widely available.'



_heading3 'Mathematics and Entire Universe All Always Equivalent to Just One Single Instruction
(Turing Completeness)'

_t 'One single instruction is sufficient to implement a computer which can emulate all operations of all functions (ie. is &#39;turing complete&#39;). Some such computers use &#39;move&#39;, some are based on addition, some use subtraction. One single instruction is sufficient to compute anything that could possibly happen in the universe.'

_heading4 'Quantum Computing is NOT Special'
_t 'Such simple computers can also emulate quantum computers. Quantum computing also does nothing that cannot be done by another computer, only performing some very specialized operations faster, because quantum bits can be both 0 and 1 simulatenously, until all bits are collapsed to the definite state of an answer. One problem in particular is solved faster by quantum computing - halving the search space for a guess. If an algorithm produces meaningful information only from a number with 2^128 possible combinations, then a quantum computer find that number with on the order of 2^64 operations instead of 2^128.

Quantum computer hardware is comparably complex and expensive to classical computer hardware, so aside from urgently necessitating replacement of some equipment using some older ciphers, as well as possibly simulating some replacement wetware (ie. misfolding proteins), quantum computing has an thoroughly unremarkable usefulness in solving problems.'


_t '





'
_heading2 'Cognition vs Automation'

_t 'Humans inevitably understand the mechanics of their world in the same way as any animal with a complex learning biological neural network (ie. *cognition*) - ~300bits per second shoving things around, ~10Mbits per second observing effects, >>1Tbits iteratively computing valid models of how these outputs cause these inputs. Very few decisions (shove) cause large changes in the surrounding world (avalanche) which may be computationally expensive to adequately model (thinking about vibrations and sensitivity through of a chain of many objects between shove and avalanche).

Interactive experimentation is thus a fundamental necessity, as with cats learning depth perception in a critical period only by interaction, and symbolic manipulation on paper/computer is only important for lack of resources, always inferior to and less enjoyable than intuitive experimentation. Arithmetic as an example, tallying quantity, is simply four *automation* functions better suited to a pocket calculator and also not well enough integrated with human *cognition*.'



_page ' ' ###

_heading2 'Noise, Signals, Normality, Abnormality, Signaling Rate, Spread Spectrum, Channels, Coded Signals as Noise, Cryptography'

_heading3 'Noise is random. Signals are not random.'

_r '<figure style="width:350px;float:right;margin: 0 0 0 15px;border: 5px solid transparent;">
	<img src="./_lib/zSPECIAL-images/images-external/waterfall_noise/mod/Splatter_Q9.jpg" alt="" style="width:100%" ><figcaption style="font-size: 0.70em;">&#39;CC BY-SA 4.0&#39; &#39;Splatter_Q9.jpg&#39; see &#39;ATTRIBUTION&#39;</figcaption>
</figure>'

_t 'Random noise does occur. Atmospheric turbulence (eg. from an air vent or fan) produces an essentially random acoustic noise. A clear whistle, on at some times, and off at others, at the same amplitude, is equally recognizable. 

Complex signals can be correlated if in any way different from noise. Over a long time, a pattern of on/off from a whistle can be added and substracted to a &#39;score&#39; for whether a code is present as amplitude shifts in a frequency bin. Searching that frequency bin for that matching code at many possible beginning times, is the cross-correlation technique that is the basis for reliably communicating, slowly, over noisy channels (eg. &#39;WSPR&#39; over amateur radio), seemingly at amplitudes below the &#39;noise floor&#39; (because On/Off-Keying code score is a much higher amplitude than the background noise).'




_heading3 'Noise distributions, patterns from random events.'

_t 'Random noise distributions exist - in which random events distribute things into a non-random pattern. One common such pattern is a &#39;normal distribution&#39;. 

Random events can distribute objects into a non-random pattern, randomly forming a random distribution. What has a number within the usual range for that distribution may be noise. What has a number very rarely occurring in that distribution (eg. only 1% likely) may be regarded as signal. Whether two random noise distributions are from events that distribute things significantly differently can also be compared on the basis of likelihood of events in one distribution occurring in another

A particularly common random noise distribution is known as a &#39;normal&#39; distribution (aka. &#39;bell curve&#39;). Numbers outside the usual range for a &#39;normal distribution&#39; are likely non-random, possibly describable as &#39;atypical&#39; or &#39;abnormal&#39;. Atypical is not always abnormal or otherwise undesirable in any way, especially where there is any possibility diversity may be valuable. Usually, likely non-random is at least regarded as a possible signal.'
_image "./_lib/zSPECIAL-images/images-illustrated/normalDistribution.png"



_heading3 'Signaling Rate as Signal to Noise Ratio'
_o _safeEcho_newline 'bitsPerSecond == hertz * log2(1 + (signal_decibels / noise_decibels) )'
_t '

Shannon-Hartley theorem is a simple equation specifying that communications bandwidth, in bits per second, is proportional to bandwidth used, in hertz, signal power, and noise power. Statistically, more samples are needed to distinguish barely significant signals from a noisy background, than more substantial signals from a quiet background.

For this reason, it is common for people to speak louder (ie. at greater amplitude) in a noisy, rather than quiet, room, especially if convinced they have important information which may not have been heard.'



_heading3 'Spread Spectrum'

_t 'Spread spectrum modulates a small amount of information (ie. a single symbol) (eg. one On/Off-Keying event) is modulated with a complex code, creating a complex signal. Receivers may correlate such complex signals as different from noise. Usually, spread spectrum devices will transmit information rather quickly. As an inevitable side effect, the bandwidth of any transmission of such information - such as a radio transmission - is increased to approximately the rate of the spreading code - in radio communications the difference tends to be from a few Hz or kHz to >>1MHz .

Spread spectrum codes are often close enough to random noise to convert an obviously non-random signal (eg. morse code beeps) into something matching background noise (eg. static noise statistically similar to atmospheric and receiver thermal noise), however, any symbol codes used for communication may be chosen to resemble random noise without such &#39;spreading&#39;.

As an example, modulating morse code switching the transmit key at a much faster rate, using a unique code of on/off timings, which a receiver could correlate, would be spread spectrum.
'


_heading3 'Channels'

_t 'A shared communications channel may be partitioned in four ways. Frequency Division Multiple Access (FDMA), Time Division Multiple Access (TDMA), Code Division Multiple Access (CDMA), and Space Division Multiple Access (SDMA).

Frequency Division Multiple Access (FDMA) usually takes advantage of the ability to separate frequencies with resistors/capacitors/inductors. Such frequency filters can be robust and made from common wire and foil (radio), tuning forks or wooden cavities (audio), etc. Frequency division is less favored for modern digital computer communications software modulation/demodulation obviates several issues. Notably, hardware many frequency filters must be stacked repeatedly to sharply attenuate adjacent frequencies, and adding the ability to change the bandwidth and frequency of many filters adds to that expense.

Time Division Multiple Access (TDMA) divides channel into time slots. Protocols must retransmit after collisions occur, possibly even from highly attenuated distant transmitters that could have been ignored by some code division. Very common in digital radio communications.

Code Division Multiple Access (CDMA) divides channel by different spreading codes. As a spread spectrum technique, a receiver listening for one code will receive all other codes as seemingly random noise. CMDA at low bit rates in software implementations may correlate very weak coded signals (ie. symbols) from the severe noise of many transmitters. Apparent noise from irrelevant transmitters may be reduced, and signal capacity correspondingly increased, if all CDMA transmitters cooperatively minimize transmit power upon demand by receiver. CDMA at high bit rates and/or in hardware implementations, with a synchronized clock, frequency mixer, low-pass filter, and comparator, may exceed reasonable received power limits (ie. many watts of power at receiver amplifiers causing distortion), may exceed hardware signal/noise limits (ie. low-pass filter thermal noise), etc, from noise of many ( >>1000 ) transmitters. CDMA has been used in digital radio communications (eg. apparently &#39;EVDO&#39;).

Space Division Multiple Access (SDMA) deliberately points transmissions (ie. by physically moving an antenna or switching parts of the antenna) in the direction of &#39;less busy&#39; receivers.


Combining FDMA, TDMA, CDMA, SDMA, has been done. Radio systems usually have some frequency filtering (FDMA) either incidentally due to antenna, or purposefully to protect their receivers from distortion due to strong out-of-band signals. CDMA may be combined with TDMA, using codes, but not all users transmitting simultaneously. SDMA is increasingly common as many low-Earth internet satellite services have many separate satellites, but each individual satellite&#39;s radio bandwidth is shared by multiple users through FDMA, TDMA, and/or CDMA.'



_heading3 'Coded Signals as Apparent Noise'

_t 'Correlating long or complex coded has the interesting property that to any receiver not aware of the code, if the code was chosen to resemble ambient random noise, it may be impossible to detect, especially if transmitted at the minimum power demanded by receiver.

For unintended receivers to be unable to guess the code, all of the code must be thoroughly unpredictable. For such communication, it is necessary that the symbols chosen cover 100% of the bit space (eg. if using 8-bit codes, all 256 symbols must be used equally), and that the symbols transmitted be *pure* ciphertext.

Receiving pure ciphertext requires attempting to decrypt incoming symbols at many possible beginning times, similar to the cross-correlation technique that is the basis for reliably communicating, slowly, over noisy channels.

Such is very rare in digital radio communications, seemingly because software developers are more immediately concerned with quickly developing technology for communicating quickly (high-bit rate).

Satellite navigation systems seem to have some such features.'



_heading3 'Cryptography'

_r '<figure style="width:150px;float:right;margin: 0 0 0 15px;border: 5px solid transparent;">
	<img src="./_lib/zSPECIAL-images/images-external/ecb_image_encryption/orig/Tux_ecb.jpg" alt="" style="width:100%" ><figcaption style="font-size: 0.70em;">&#39;Larry Ewing&#39; &#39;lewing@isc.tamu.edu&#39; &#39;The GIMP&#39; &#39;Tux_ecb.jpg&#39; see &#39;ATTRIBUTION&#39;</figcaption>
</figure>'

_r '<figure style="width:250px;float:right;margin: 0 0 0 15px;border: 5px solid transparent;">
	<img src="./_lib/zSPECIAL-images/images-external/asymmetric_crypto/orig/Public_key_encryption.svg" alt="" style="width:100%" ><figcaption style="font-size: 0.70em;">&#39;Public_key_encryption.svg&#39; see &#39;ATTRIBUTION&#39;</figcaption>
</figure>'

_t 'Cryptography combines a signal of &#39;plaintext&#39; (non-random symbols) with a code of random symbols known only to intended recipients, to create &#39;ciphertext&#39; indistinguishable from random noise in any way by anyone who does not possess the code. Cryptography can be *impossible* to &#39;break&#39;, because ciphertext can be impossible to recognize as anything other than random numbers (eg. from tossing dice).'


_heading4 'A Perfect Cipher for Dummies and the Basis of All Ciphers - One-Time-Pad'

_t 'Message on one paper. Random letters (or whatever symbols) on another paper (the &#39;One-Time-Pad&#39;). Number the symbols from 1 to the maximum number (ie. 26 for A-Z). Add the random letters to the message letters, carrying any number above the maximum to a lower number (ie. modular arithmetic). Encryption complete. Without the random letters paper, the &#39;ciphertext&#39; is *impossible* to distinguish from random noise.

Because the one-time-pad has as many symbols as the plaintext/ciphertext, the key is as &#39;large&#39; as any encrypted message, the one-time-pad is rather inconvenient. A &#39;one-time-pad&#39; cannot be memorized as a password to decrypt megabytes of files, a shared one-time-pad must be physically transported to all recipients, and any new one-time pad sent using a one-time-pad can only be as large as the original one-time-pad. Nevertheless, this has historically been used for historic communications, notably SIGSALY (which included many substantial and significant non-cryptography technical achievements), and may be used for some communications today.

Two ciphertexts from the same &#39;one-time-pad&#39; can be easily decrypted by widely available statistical methods, so a one-time pad must not be used twice. Similarly, the pad itself must use strictly random numbers, any predictability can be found by widely available statistical methods, allowing the pad to be inferred, and the message made readable.

Ciphertext always uses all used symbols equally often, as to do otherwise would not exactly resemble randomness. Notably, it is not possible to create or meaningfully change encrypted messages without the &#39;secret&#39;, due to the exact resemblance of randomness. Authentication uses encryption in any of many schemes, due to the unforgeability of meaningful encrypted messages.'


_heading4 'Symmetric Ciphers'

_t 'Symmetric ciphers use a small key (eg. 256bits) of random numbers to create a large (usually unlimited) quantity of equally unpredictable random numbers. Such symbols recreate the effect of a one-time-pad, as any intended persons with the small key can generate the same string of random numbers for both encryption and decryption.

Stream ciphers directly combine the large quantity of random symbols with plaintext, producing ciphertext. Block ciphers can take a fixed quantity of plaintext symbols, and convert to ciphertext by several operations of addition, shifting, lookup substitution, mixing, etc. Block ciphers, when given a long string of &#39;0&#39; or other predictably meaningless numbers, still produces unpredictable random ciphertext, and so may be used as a stream cipher.

Symmetric ciphers are infeasible to &#39;break&#39; if the stream of ciphertext cannot be statistically proven. Expert consensus is that many of the commonly used symmetric ciphers (ie. AES finalists) will not be broken by any computer or statistical analysis until long after any protected plaintext is no longer of any consequence to the originating parties (ie. long after their biological lifespans have expired), or until well after the universe itself ceases to have any non-randomness in it.


Symmetric ciphers are still sometimes chosen for convenience rather than security, resulting in some unmet expectations (eg. Wired Equivalent Protection). Block ciphers specifically can be misused in that input plaintext must always be unique, becoming a more of an alphabet substitution table than a cipher (ie. ECB mode) when this is not properly guaranteed (eg. by mixing plaintext blocks with an incrementing number for each block).'


_heading4 'Asymmetric Ciphers'

_t 'Asymmetric ciphers create a string of random numbers from an encryption key which can only be recreated for that specific message or with a separate decryption key.

Two (or more) parties can issue public encryption keys, allowing anyone to encrypt a message, which only they can decrypt with their private keys. Thus, both parties can create a private encrypted communications channel in public, and authenticate theirselves by completing the challenge of decrypting a message intended for theirselves, using the private encrypted communications channel.

In principle, pure ciphertext messages, in a noisy (eg. radio) channel, could establish a brief conversation, unlocatable and undetectable to a third party, with no &#39;pairing&#39; of shared keys in advance.


Quantum computing is a risk to some asymmetric ciphers, for ciphers which use the specific mathematical operations quantum superposition can much more quickly predict (eg. elliptic curves, prime numbers). Replacing those algorithms is becoming an urgent issue, especially presenting some risk to bank accounts, bank solvency, and popular cryptocurrencies.'




_page ' ' ###

_heading2 'Amplitude, Time, Frequency'

_r '<figure style="width:500px;float:right;margin: 0 0 0 15px;border: 5px solid transparent;">
	<img src="./_lib/zSPECIAL-images/images-external/circle_tracing_sine_wave/mod/ComplexSinInATimeAxe.gif" alt="" style="width:100%" ><figcaption style="font-size: 0.70em;">&#39;ComplexSinInATimeAxe.gif&#39; see &#39;ATTRIBUTION&#39;</figcaption>
</figure>'
_t 'Amplitude is a measure of &#39;how much&#39;. Amplitude could be pressure, voltage, current, or even the water level in a container. Often amplitude is measured on the vertical axis of a (eg. oscilloscope) graph.

Time is simply how long it takes one event to proceed to the next, usually measured in the SI unit, seconds.

Frequency is the inverse of time, measured in cycles per second, or hertz. An alternating current of 60Hz reverses direction 60 times per second. At this frequency, one cycle lasts 1/60th of a second.

Any change in amplitude over time gives rise to a signal with a frequency. A pure sine wave changes amplitude at a constant rate, tracing a circle. By contrast, a square wave sharply changes amplitude, giving rise to one large fundamental frequency, and many smaller amplitude harmonics. A pulse of energy is in fact a square wave, and the sudden transition from no amplitude, to amplitude, then back to no amplitude, gives rise to a wide range of frequencies.

In practical terms, this is why switching power supplies, which deliver power one pulse at a time, generate substantial electrical noise, which results in external electrical or magnetic fields that give rise to radio wave photons, and thus, random noise on radios. Arcing electrical circuits, where energy is switched on and off repeatedly as the arc is ignited and extinguished, are also a major source of electrical/radio interference. Since a major mathematical approach to analyzing signals is by measuring frequency, this is can be very substantially undesirable in communications and diagnostic equipment.

Old analog TV and AM or single-side-band radios tend to show interference noticeably when large motors (eg. vacuum cleaners) or switching power supplies are near their sensitive receiver circuits (eg. in the same house), due to square wave &#39;harmonics&#39; and frequency mixing with other rapidly switched frequencies (eg. computers with rapidly switching loads powered by rapidly switching power supplies converting power one switched packet at a time).



Modulating the amplitude of an oscillating sine wave with the amplitude of another sine wave of a different frequency - such a frequency mixer being as simple as a single light dependent resistor and an LED light - or a JFET transistor - tends to produce two more frequencies - the sum and difference of the multiplying frequency. Thus, one frequency (eg. 1kHz) may be shifted to two others (eg. 1GHz+1kHz, 1GHz-1kHz). Removing one of these frequencies (eg. with a pair of frequency mixing devices) is the basis for &#39;single-sideband&#39; - the direct shifting of one frequency (eg. 0-20kHz audio) to another (eg. 1GHz). Thus, a computer sound card with a maximum frequency of 20kHz can directly and exactly process phase, frequency, and amplitude shifts at radio frequency of (arbitrarily) 1GHz, as a &#39;software radio&#39; (though today digital communications often use sound card equivalent hardware with >>10MHz of &#39;baseband&#39; bandwidth to send >>10Mbits/s).


Thus, frequency modulation, phase modulation, amplitude modulation, single-side-band modulation, are all equivalent. Such terms are more descriptive of the hardware or software specifically used, with &#39;On/Off Keying&#39; being rather typical. Frequency modulation sometimes is used because such analog phase-locked loop hardware can do some &#39;spreading&#39; to reduce noticeable received interference. Some multiple phase shift keying or multiple amplitude shift keying are actually equivalent in effect (eg. QPSK, QAM) and transmitted very simply by putting one of a few specified amplitudes into a frequency mixer depending on the current intended symbol. Digital communication modulation schemes are often described by terminology having much more to do with how they *are* implemented than how they *can* be implemented.'






